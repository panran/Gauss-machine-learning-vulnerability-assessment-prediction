#!/usr/bin/env python
#-*- coding:utf8 -*-
import requests
from  bs4 import BeautifulSoup
import traceback
import re
import xlwt
import time
page =[]

def getHTMLTEXT(url,code="utf-8"):
    kv = {'user-agent': 'Mozilla/5.0'}
    try:
        r=requests.get(url,headers=kv,timeout=800)
        r.raise_for_status()
        r.encoding=code
        return r.text
    except:
        traceback.print_exc()
        return ""

def parsepage(url,page):

    html=getHTMLTEXT(url)
    soup=BeautifulSoup(html,'html.parser')
    #print(soup)
    text=soup.find_all('a',href=re.compile("vuln/detail/CVE"))
    #获得带有漏洞编号的标签
    mess = soup.find_all(attrs={"data-testid": re.compile("vuln-summary")})
    # 获得漏洞详细的描述信息

    for i in range(20):
        vulu=re.findall(r"(?<=vuln/detail/).+?(?=\")",str(text[i]))
        me=re.findall(r'<p .*?>(.*?)</p>', str(mess[i]))
        sheet1.write(1+i+page*20,0,vulu)
        sheet1.write(1+i+page*20,1,me)
        print("漏洞CVE编号：",vulu)
        print("漏洞描述信息：",me)
        print()

if __name__=="__main__":
    url_NVD_Linux='https://nvd.nist.gov/vuln/search/results?form_type=Basic&results_type=overview&query=linux&search_type=all&startIndex='
    file = xlwt.Workbook()
    sheet1 = file.add_sheet(u'sheet1', cell_overwrite_ok=True)
    sheet1.write(0, 0, "漏洞CVE编号")
    sheet1.write(0, 1, "漏洞详细描述")
    filename = "../data/"+'NVD漏洞描述信息' + time.strftime('%Y-%m-%d', time.localtime(time.time())) + '.xls'

    for i in range(70):
        s=(i*20).__str__()
        print(url_NVD_Linux+s)
        parsepage(url_NVD_Linux+s,i)
    
    file.save("../data/"+filename)